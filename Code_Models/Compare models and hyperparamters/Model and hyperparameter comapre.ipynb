{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "V28"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from scipy.stats import randint\n",
        "from google.colab import drive\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Load the data\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Dataset/X_Train_Data_Input.csv')\n",
        "Y_train = pd.read_csv('/content/drive/MyDrive/Dataset/Y_Train_Data_Target.csv')\n",
        "\n",
        "# Drop ID columns\n",
        "X_train.drop(columns=['ID'], inplace=True)\n",
        "Y_train.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "# Sample a smaller subset of the dataset (e.g., 10% of the data)\n",
        "X_train, _, Y_train, _ = train_test_split(X_train, Y_train['target'], test_size=0.9, random_state=42)  # Retaining only 10%\n",
        "\n",
        "# Identify numeric and categorical features\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create transformers for numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply the transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Feature Selection using RandomForest to get feature importances\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_preprocessed, Y_train)\n",
        "top_feature_indices = np.argsort(rf.feature_importances_)[-10:]  # Select top 10 features\n",
        "X_train_selected = X_train_preprocessed[:, top_feature_indices]\n",
        "\n",
        "# Split the data for validation (80% train, 20% validation)\n",
        "X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train_selected, Y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Define models to evaluate\n",
        "models = {\n",
        "    'Random Forest': RandomForestClassifier(),\n",
        "    'Gradient Boosting': GradientBoostingClassifier(),\n",
        "    'Logistic Regression': LogisticRegression(max_iter=1000),\n",
        "    'Support Vector Classifier': SVC(probability=True),\n",
        "    'Decision Tree': DecisionTreeClassifier()\n",
        "}\n",
        "\n",
        "# Store results for comparison\n",
        "results = {}\n",
        "\n",
        "# Iterate through each model and evaluate performance\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name}...\")\n",
        "\n",
        "    # Hyperparameter tuning for Random Forest and Gradient Boosting\n",
        "    param_distributions = {}\n",
        "    if name == 'Random Forest':\n",
        "        param_distributions = {\n",
        "            'n_estimators': randint(100, 300),\n",
        "            'max_depth': randint(3, 8)\n",
        "        }\n",
        "    elif name == 'Gradient Boosting':\n",
        "        param_distributions = {\n",
        "            'n_estimators': randint(100, 300),\n",
        "            'learning_rate': [0.01, 0.1, 0.2],\n",
        "            'max_depth': randint(3, 8)\n",
        "        }\n",
        "\n",
        "    # Use RandomizedSearchCV for hyperparameter tuning if applicable\n",
        "    if param_distributions:\n",
        "        random_search = RandomizedSearchCV(model, param_distributions, n_iter=30, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
        "        random_search.fit(X_train_split, Y_train_split)\n",
        "        best_model = random_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train_split, Y_train_split)\n",
        "        best_model = model\n",
        "\n",
        "    # Make predictions\n",
        "    Y_pred = best_model.predict(X_val_split)\n",
        "\n",
        "    # Store evaluation metrics\n",
        "    results[name] = {\n",
        "        'accuracy': accuracy_score(Y_val_split, Y_pred),\n",
        "        'report': classification_report(Y_val_split, Y_pred, output_dict=True),\n",
        "        'confusion_matrix': confusion_matrix(Y_val_split, Y_pred)\n",
        "    }\n",
        "\n",
        "    # Print evaluation metrics\n",
        "    print(f\"Validation Accuracy for {name}: {results[name]['accuracy']}\")\n",
        "    print(\"Validation Classification Report:\\n\", classification_report(Y_val_split, Y_pred))\n",
        "    print(\"Validation Confusion Matrix:\\n\", confusion_matrix(Y_val_split, Y_pred))\n",
        "\n",
        "# Load the test data\n",
        "Dtest = pd.read_csv('/content/drive/MyDrive/Dataset/X_Test_Data_Input.csv')\n",
        "Y_test = pd.read_csv('/content/drive/MyDrive/Dataset/Y_Test_Data_Target.csv')  # Assuming you have the true labels\n",
        "Dtest_id = Dtest['ID']\n",
        "Dtest.drop(columns=['ID'], inplace=True)\n",
        "\n",
        "# Apply the same transformations to the test data\n",
        "Dtest_preprocessed = preprocessor.transform(Dtest)\n",
        "Dtest_selected = Dtest_preprocessed[:, top_feature_indices]\n",
        "\n",
        "# Evaluate models on the test data\n",
        "for name, model in models.items():\n",
        "    print(f\"\\nEvaluating {name} on test data...\")\n",
        "\n",
        "    # If using hyperparameter tuned model\n",
        "    if name in ['Random Forest', 'Gradient Boosting']:\n",
        "        random_search.fit(X_train_selected, Y_train)\n",
        "        best_model = random_search.best_estimator_\n",
        "    else:\n",
        "        model.fit(X_train_selected, Y_train)\n",
        "        best_model = model\n",
        "\n",
        "    # Make predictions on the test set\n",
        "    Y_pred_test = best_model.predict(Dtest_selected)\n",
        "\n",
        "    # Print evaluation metrics for test data\n",
        "    print(f\"Test Accuracy for {name}: {accuracy_score(Y_test['target'], Y_pred_test)}\")\n",
        "    print(\"Test Classification Report:\\n\", classification_report(Y_test['target'], Y_pred_test))\n",
        "    print(\"Test Confusion Matrix:\\n\", confusion_matrix(Y_test['target'], Y_pred_test))\n",
        "\n",
        "    # Prepare the submission file\n",
        "    submission = pd.DataFrame({'ID': Dtest_id, 'target': Y_pred_test})\n",
        "    submission.to_csv(f'submission_{name}.csv', index=False)  # Save submission files with model names\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F7KxaQg-3-Y2",
        "outputId": "5da29c89-3f68-42de-92dd-e67a01e4c558"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "\n",
            "Evaluating Random Forest...\n",
            "Validation Accuracy for Random Forest: 0.9764376233840667\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     14214\n",
            "           1       0.83      0.95      0.88      1489\n",
            "\n",
            "    accuracy                           0.98     15703\n",
            "   macro avg       0.91      0.96      0.94     15703\n",
            "weighted avg       0.98      0.98      0.98     15703\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[13923   291]\n",
            " [   79  1410]]\n",
            "\n",
            "Evaluating Gradient Boosting...\n",
            "Validation Accuracy for Gradient Boosting: 0.9765649875819907\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99     14214\n",
            "           1       0.83      0.94      0.88      1489\n",
            "\n",
            "    accuracy                           0.98     15703\n",
            "   macro avg       0.91      0.96      0.94     15703\n",
            "weighted avg       0.98      0.98      0.98     15703\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[13930   284]\n",
            " [   84  1405]]\n",
            "\n",
            "Evaluating Logistic Regression...\n",
            "Validation Accuracy for Logistic Regression: 0.968859453607591\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98     14214\n",
            "           1       0.80      0.89      0.84      1489\n",
            "\n",
            "    accuracy                           0.97     15703\n",
            "   macro avg       0.89      0.94      0.91     15703\n",
            "weighted avg       0.97      0.97      0.97     15703\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[13884   330]\n",
            " [  159  1330]]\n",
            "\n",
            "Evaluating Support Vector Classifier...\n",
            "Validation Accuracy for Support Vector Classifier: 0.9729987900401197\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98     14214\n",
            "           1       0.80      0.94      0.87      1489\n",
            "\n",
            "    accuracy                           0.97     15703\n",
            "   macro avg       0.90      0.96      0.93     15703\n",
            "weighted avg       0.98      0.97      0.97     15703\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[13873   341]\n",
            " [   83  1406]]\n",
            "\n",
            "Evaluating Decision Tree...\n",
            "Validation Accuracy for Decision Tree: 0.9684136789148571\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98     14214\n",
            "           1       0.83      0.84      0.83      1489\n",
            "\n",
            "    accuracy                           0.97     15703\n",
            "   macro avg       0.91      0.91      0.91     15703\n",
            "weighted avg       0.97      0.97      0.97     15703\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[13958   256]\n",
            " [  240  1249]]\n",
            "\n",
            "Evaluating Random Forest on test data...\n",
            "Test Accuracy for Random Forest: 0.9759735892889895\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99    237034\n",
            "           1       0.82      0.95      0.88     24678\n",
            "\n",
            "    accuracy                           0.98    261712\n",
            "   macro avg       0.91      0.96      0.93    261712\n",
            "weighted avg       0.98      0.98      0.98    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[231993   5041]\n",
            " [  1247  23431]]\n",
            "\n",
            "Evaluating Gradient Boosting on test data...\n",
            "Test Accuracy for Gradient Boosting: 0.9759583053127101\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99    237034\n",
            "           1       0.82      0.95      0.88     24678\n",
            "\n",
            "    accuracy                           0.98    261712\n",
            "   macro avg       0.91      0.96      0.93    261712\n",
            "weighted avg       0.98      0.98      0.98    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[231989   5045]\n",
            " [  1247  23431]]\n",
            "\n",
            "Evaluating Logistic Regression on test data...\n",
            "Test Accuracy for Logistic Regression: 0.9688321513725011\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98    237034\n",
            "           1       0.80      0.90      0.84     24678\n",
            "\n",
            "    accuracy                           0.97    261712\n",
            "   macro avg       0.89      0.94      0.91    261712\n",
            "weighted avg       0.97      0.97      0.97    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[231344   5690]\n",
            " [  2467  22211]]\n",
            "\n",
            "Evaluating Support Vector Classifier on test data...\n",
            "Test Accuracy for Support Vector Classifier: 0.9728938680687168\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.98    237034\n",
            "           1       0.80      0.95      0.87     24678\n",
            "\n",
            "    accuracy                           0.97    261712\n",
            "   macro avg       0.90      0.96      0.93    261712\n",
            "weighted avg       0.98      0.97      0.97    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[231172   5862]\n",
            " [  1232  23446]]\n",
            "\n",
            "Evaluating Decision Tree on test data...\n",
            "Test Accuracy for Decision Tree: 0.9668605184324754\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.98      0.98      0.98    237034\n",
            "           1       0.82      0.83      0.82     24678\n",
            "\n",
            "    accuracy                           0.97    261712\n",
            "   macro avg       0.90      0.90      0.90    261712\n",
            "weighted avg       0.97      0.97      0.97    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[232644   4390]\n",
            " [  4283  20395]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler, OneHotEncoder\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
        "from sklearn.compose import ColumnTransformer\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
        "from scipy.stats import randint\n",
        "\n",
        "# Load the data\n",
        "X_train = pd.read_csv('/content/drive/MyDrive/Dataset/X_Train_Data_Input.csv')\n",
        "Y_train = pd.read_csv('/content/drive/MyDrive/Dataset/Y_Train_Data_Target.csv')\n",
        "\n",
        "# Drop ID columns from both X_train and Y_train\n",
        "X_train = X_train.drop(columns=['ID'])\n",
        "Y_train = Y_train.drop(columns=['ID'])\n",
        "\n",
        "# Identify numeric and categorical features\n",
        "numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\n",
        "categorical_features = X_train.select_dtypes(include=['object']).columns\n",
        "\n",
        "# Create transformers for numeric and categorical data\n",
        "numeric_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='mean')),\n",
        "    ('scaler', StandardScaler())\n",
        "])\n",
        "\n",
        "categorical_transformer = Pipeline(steps=[\n",
        "    ('imputer', SimpleImputer(strategy='most_frequent')),\n",
        "    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n",
        "])\n",
        "\n",
        "# Combine transformers into a preprocessor\n",
        "preprocessor = ColumnTransformer(\n",
        "    transformers=[\n",
        "        ('num', numeric_transformer, numeric_features),\n",
        "        ('cat', categorical_transformer, categorical_features)\n",
        "    ])\n",
        "\n",
        "# Apply the transformations\n",
        "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
        "\n",
        "# Feature Selection using RandomForest to get feature importances\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf.fit(X_train_preprocessed, Y_train['target'])\n",
        "importances = rf.feature_importances_\n",
        "top_feature_indices = np.argsort(importances)[-10:]  # Select top 10 features\n",
        "\n",
        "X_train_selected = X_train_preprocessed[:, top_feature_indices]\n",
        "\n",
        "# Split the data for validation (80% train, 20% validation)\n",
        "X_train_split, X_val_split, Y_train_split, Y_val_split = train_test_split(X_train_selected, Y_train['target'], test_size=0.2, random_state=42)\n",
        "\n",
        "# Define the model (GradientBoostingClassifier)\n",
        "model = GradientBoostingClassifier()\n",
        "\n",
        "# Define hyperparameter search space\n",
        "param_distributions = {\n",
        "    'n_estimators': randint(100, 300),\n",
        "    'learning_rate': [0.01, 0.1, 0.2],\n",
        "    'max_depth': randint(3, 8)\n",
        "}\n",
        "\n",
        "# Hyperparameter tuning using RandomizedSearchCV\n",
        "random_search = RandomizedSearchCV(model, param_distributions, n_iter=30, scoring='accuracy', cv=3, random_state=42, n_jobs=-1)\n",
        "random_search.fit(X_train_split, Y_train_split)\n",
        "\n",
        "# Best model from hyperparameter tuning\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Predict on validation set\n",
        "Y_pred_val = best_model.predict(X_val_split)\n",
        "\n",
        "# Print evaluation metrics for validation set\n",
        "print(\"Best Hyperparameters:\", random_search.best_params_)\n",
        "print(\"Validation Accuracy:\", accuracy_score(Y_val_split, Y_pred_val))\n",
        "print(\"Validation Classification Report:\\n\", classification_report(Y_val_split, Y_pred_val))\n",
        "print(\"Validation Confusion Matrix:\\n\", confusion_matrix(Y_val_split, Y_pred_val))\n",
        "\n",
        "# Load the test data\n",
        "Dtest = pd.read_csv('/content/drive/MyDrive/Dataset/X_Test_Data_Input.csv')\n",
        "Y_test = pd.read_csv('/content/drive/MyDrive/Dataset/Y_Test_Data_Target.csv')  # Assuming you have the true labels\n",
        "\n",
        "# Drop ID column from test data\n",
        "Dtest = Dtest.drop(columns=['ID'])\n",
        "\n",
        "# Impute missing values in test data\n",
        "Dtest = pd.DataFrame(SimpleImputer(strategy='mean').fit_transform(Dtest), columns=Dtest.columns)\n",
        "\n",
        "# Apply the same preprocessing and feature selection to the test data\n",
        "Dtest_preprocessed = preprocessor.transform(Dtest)\n",
        "Dtest_selected = Dtest_preprocessed[:, top_feature_indices]\n",
        "\n",
        "# Predict on the test set\n",
        "Y_pred_test = best_model.predict(Dtest_selected)\n",
        "\n",
        "# Print evaluation metrics for test set\n",
        "print(\"Test Accuracy:\", accuracy_score(Y_test['target'], Y_pred_test))\n",
        "print(\"Test Classification Report:\\n\", classification_report(Y_test['target'], Y_pred_test))\n",
        "print(\"Test Confusion Matrix:\\n\", confusion_matrix(Y_test['target'], Y_pred_test))\n",
        "\n",
        "# Prepare the submission file\n",
        "submission = pd.DataFrame({'ID': Dtest_id, 'target': Y_pred_test})\n",
        "submission.to_csv('submission.csv', index=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iBZxVfENajnX",
        "outputId": "284e4bac-9207-4ae0-945c-9b068223ff07"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Hyperparameters: {'learning_rate': 0.1, 'max_depth': 7, 'n_estimators': 188}\n",
            "Validation Accuracy: 0.9766728014927369\n",
            "Validation Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99    142275\n",
            "           1       0.84      0.93      0.88     14752\n",
            "\n",
            "    accuracy                           0.98    157027\n",
            "   macro avg       0.92      0.95      0.93    157027\n",
            "weighted avg       0.98      0.98      0.98    157027\n",
            "\n",
            "Validation Confusion Matrix:\n",
            " [[139702   2573]\n",
            " [  1090  13662]]\n",
            "Test Accuracy: 0.9766384422571376\n",
            "Test Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.98      0.99    237034\n",
            "           1       0.84      0.93      0.88     24678\n",
            "\n",
            "    accuracy                           0.98    261712\n",
            "   macro avg       0.92      0.96      0.93    261712\n",
            "weighted avg       0.98      0.98      0.98    261712\n",
            "\n",
            "Test Confusion Matrix:\n",
            " [[232585   4449]\n",
            " [  1665  23013]]\n"
          ]
        }
      ]
    }
  ]
}